<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.101.0"><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Efficient Query Parallelism in Cortex with Dynamic Query Splitting | Cortex</title><meta name=description content="This article explores the motivations behind adapting dynamic query splitting in Cortex, how the dynamic model works, and how to configure it for more efficient scalable PromQL query execution.
"><meta property="og:title" content="Efficient Query Parallelism in Cortex with Dynamic Query Splitting"><meta property="og:description" content="This article explores the motivations behind adapting dynamic query splitting in Cortex, how the dynamic model works, and how to configure it for more efficient scalable PromQL query execution.
"><meta property="og:type" content="article"><meta property="og:url" content="/blog/2025/08/12/efficient-query-parallelism-in-cortex-with-dynamic-query-splitting/"><meta property="og:image" content="/images/logo-twitter-card.jpg"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-08-12T00:00:00+00:00"><meta property="article:modified_time" content="2025-10-01T15:45:24+09:00"><meta property="og:site_name" content="Cortex"><meta itemprop=name content="Efficient Query Parallelism in Cortex with Dynamic Query Splitting"><meta itemprop=description content="This article explores the motivations behind adapting dynamic query splitting in Cortex, how the dynamic model works, and how to configure it for more efficient scalable PromQL query execution.
"><meta itemprop=datePublished content="2025-08-12T00:00:00+00:00"><meta itemprop=dateModified content="2025-10-01T15:45:24+09:00"><meta itemprop=wordCount content="1675"><meta itemprop=image content="/images/logo-twitter-card.jpg"><meta itemprop=keywords content="blog,cortex,query,optimization,"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="/images/logo-twitter-card.jpg"><meta name=twitter:title content="Efficient Query Parallelism in Cortex with Dynamic Query Splitting"><meta name=twitter:description content="This article explores the motivations behind adapting dynamic query splitting in Cortex, how the dynamic model works, and how to configure it for more efficient scalable PromQL query execution.
"><link rel=preload href=/scss/main.min.5eaade7cd2a503d4fabeefa845c4a82ed6faa89fe4c763572d9fbdd72b72312d.css as=style><link href=/scss/main.min.5eaade7cd2a503d4fabeefa845c4a82ed6faa89fe4c763572d9fbdd72b72312d.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-SRR0DSREGX"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-SRR0DSREGX",{anonymize_ip:!1})}</script></head><body class="td-page td-blog"><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar navbar-nocover"><a id=cortex-logo class=navbar-brand href=/><span class=navbar-logo><svg xmlns="http://www.w3.org/2000/svg" role="img" viewBox="-17.92 -14.92 1191.84 462.84"><defs><style>.cls-1{fill:#fff}</style></defs><path d="M214.531 8.017C99.353 8.017 5.65 101.72 5.65 216.899S99.353 425.78 214.531 425.78s208.882-93.704 208.882-208.882S329.71 8.017 214.531 8.017zm0 408.558c-110.102.0-199.676-89.574-199.676-199.676S104.429 17.222 214.53 17.222 414.208 106.797 414.208 216.9 324.633 416.575 214.53 416.575z" class="cls-1"/><circle cx="327.452" cy="221.633" r="34.571" class="cls-1"/><circle cx="213.713" cy="353.584" r="34.571" class="cls-1"/><path d="M299.992 167.913l-59-56.05a34.578 34.578.0 10-4.343 4.34l57.828 54.937a60.158 60.158.0 00-27.168 49.123h-12.97l-23.456-67.02-26.055 64.718H175.73l-24.724 57.22-21.808-54.524-.063.025v-.586h-22.048a34.582 34.582.0 10-.275 6.138h18.005l25.97 64.925 28.977-67.06h29.207l21.51-53.424 19.503 55.725H267.5a60.173 60.173.0 0025.202 44.11l-56.52 56.52 4.34 4.338 57.492-57.492a60.155 60.155.0 101.977-105.963zm81.481 53.515a54.02 54.02.0 11-54.022-54.02 54.083 54.083.0 0154.022 54.02zm175.707 42.568q-8.797 8.178-24.405 8.177a34.858 34.858.0 01-17.095-3.965 33.188 33.188.0 01-11.643-10.529 46.374 46.374.0 01-6.566-14.99 71.134 71.134.0 01-2.105-17.341 86.99 86.99.0 011.982-18.706 46.804 46.804.0 016.565-15.98 34.028 34.028.0 0112.263-11.149q7.675-4.21 19.077-4.212 13.38.0 21.306 6.69 7.927 6.689 10.405 18.829h21.803a50.76 50.76.0 00-5.946-19.696 44.06 44.06.0 00-12.015-13.75 49.842 49.842.0 00-16.848-8.051 77.44 77.44.0 00-20.44-2.601q-15.114.0-26.509 5.326a52.935 52.935.0 00-18.952 14.617 62.165 62.165.0 00-11.273 21.8 94.013 94.013.0 00-3.717 26.883 86.195 86.195.0 003.84 26.386 57.783 57.783.0 0011.397 20.686 50.138 50.138.0 0018.829 13.38 66.766 66.766.0 0025.891 4.705q24.527.0 38.772-12.882 14.245-12.878 17.715-36.668h-21.556q-1.986 14.867-10.776 23.041zm157.44-87.828a56.338 56.338.0 00-19.447-14.244q-11.52-5.203-26.882-5.203-15.115.0-26.756 5.203a56.009 56.009.0 00-19.573 14.244 59.75 59.75.0 00-11.892 21.307 85.299 85.299.0 00-3.965 26.386 84.117 84.117.0 003.965 26.262 59.853 59.853.0 0011.892 21.183 54.61 54.61.0 0019.573 14.12q11.643 5.077 26.756 5.08 15.36.0 26.882-5.08a54.908 54.908.0 0019.447-14.12 59.95 59.95.0 0011.892-21.183 84.181 84.181.0 003.965-26.262 85.364 85.364.0 00-3.965-26.386 59.846 59.846.0 00-11.892-21.307zm-9.538 68.38a43.305 43.305.0 01-8.548 15.113 37.061 37.061.0 01-12.759 9.29 38.825 38.825.0 01-30.968.0 37.003 37.003.0 01-12.76-9.29 43.209 43.209.0 01-8.547-15.114 70.669 70.669.0 010-41.373 44.634 44.634.0 018.547-15.237 36.428 36.428.0 0112.76-9.415 38.826 38.826.0 0130.968.0 36.484 36.484.0 0112.76 9.415 44.735 44.735.0 018.547 15.237 70.624 70.624.0 010 41.373zm81.141-80.89q-11.147 7.434-18.83 23.041h-.493v-27.005h-19.82V287.78h21.057v-56.984a87.528 87.528.0 012.478-21.924 41.993 41.993.0 017.93-16.228 33.951 33.951.0 0114.368-10.158q8.919-3.468 21.555-3.468V156.72q-17.097-.493-28.245 6.937zm80.761-42.366h-21.06v38.402h-21.8v18.581h21.8v81.51a48.668 48.668.0 001.734 14.37 17.432 17.432.0 005.326 8.423 20.57 20.57.0 009.415 4.088 75.59 75.59.0 0013.999 1.115h16.104v-18.582h-9.664a70.335 70.335.0 01-8.05-.37 10.361 10.361.0 01-4.833-1.611 6.108 6.108.0 01-2.354-3.469 23.006 23.006.0 01-.617-5.946v-79.528h25.518v-18.581h-25.518zm148.522 60.452a56.135 56.135.0 00-18.085-17.962q-11.276-7.063-28.367-7.06a58.263 58.263.0 00-24.155 4.953A56.796 56.796.0 00925.82 175.55a63.949 63.949.0 00-12.51 21.058 77.064 77.064.0 00-4.461 26.758 102.521 102.521.0 004.338 27.004 58.87 58.87.0 0011.519 21.307 52.43 52.43.0 0018.953 13.873q11.272 4.954 26.632 4.955 21.8.0 36.173-10.901 14.364-10.898 18.58-32.455h-20.81q-2.73 12.635-11.272 18.829-8.549 6.198-21.927 6.195a43.577 43.577.0 01-18.085-3.468 35.417 35.417.0 01-12.636-9.291 36.127 36.127.0 01-7.184-13.38 50.746 50.746.0 01-1.981-15.98h95.879a102.07 102.07.0 00-2.107-24.526 71.064 71.064.0 00-9.415-23.784zm-84.357 29.73a43.81 43.81.0 013.219-13.999 37.354 37.354.0 017.433-11.52 34.013 34.013.0 0111.272-7.803 36.694 36.694.0 0114.74-2.85 36.062 36.062.0 0114.494 2.85 36.492 36.492.0 0111.398 7.68 36.107 36.107.0 017.68 11.52 43.253 43.253.0 013.345 14.122zm170.95 7.184 44.1-58.964h-25.271l-31.961 44.843-30.721-44.843h-27.006l44.595 60.698-48.063 67.389h25.518l35.677-53.019 35.676 53.019h27.006l-49.55-69.123z" class="cls-1"/></svg></span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs/><span>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/blog/><span class=active>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a href=https://twitter.com/cortexmetrics class="nav-link active"><span class=active><i class="fab fa-fw fa-twitter"></i> Twitter</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a href=https://github.com/cortexproject class="nav-link active"><span class=active><i class="fab fa-fw fa-github"></i> GitHub</span></a></li></ul></div><div class="navbar-nav d-none d-md-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.3a63ce416997a6553aaafbb11901eb64.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><div id=content-mobile><form class="td-sidebar__search d-flex align-items-center"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.3a63ce416997a6553aaafbb11901eb64.json data-offline-search-base-href=/ data-offline-search-max-results=10>
<button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-section-nav aria-expanded=false aria-label="Toggle section navigation"></button></form></div><div id=content-desktop></div><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-blog-li><a href=/blog/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-blog><span>Blog</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20250908query-priority-in-cortex-li><a href=/blog/2025/09/08/query-priority-in-cortex/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20250908query-priority-in-cortex><span>Query Priority in Cortex</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-blog20250812efficient-query-parallelism-in-cortex-with-dynamic-query-splitting-li><a href=/blog/2025/08/12/efficient-query-parallelism-in-cortex-with-dynamic-query-splitting/ title="Efficient Query Parallelism in Cortex with Dynamic Query Splitting" class="align-left pl-0 active td-sidebar-link td-sidebar-link__page" id=m-blog20250812efficient-query-parallelism-in-cortex-with-dynamic-query-splitting><span class=td-sidebar-nav-active-item>Dynamic Query Splitting</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20250804block-the-blast-how-query-rejection-protects-your-cortex-cluster-li><a href=/blog/2025/08/04/block-the-blast-how-query-rejection-protects-your-cortex-cluster/ title="Block the Blast: How Query Rejection Protects Your Cortex Cluster" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20250804block-the-blast-how-query-rejection-protects-your-cortex-cluster><span>Query Rejection in Cortex</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20250429optimizing-promql-queries-a-deep-dive-li><a href=/blog/2025/04/29/optimizing-promql-queries-a-deep-dive/ title="Optimizing PromQL queries: A deep dive" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20250429optimizing-promql-queries-a-deep-dive><span>Optimizing PromQL queries</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20250426introducing-the-cortex-blog-sharing-our-journey-li><a href=/blog/2025/04/26/introducing-the-cortex-blog-sharing-our-journey/ title="Introducing the Cortex Blog: Sharing Our Journey" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20250426introducing-the-cortex-blog-sharing-our-journey><span>Hello Cortex!</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><a href=https://github.com/cortexproject/cortex/edit/master/blog/2025/dynamic-query-splitting.md target=_blank><i class="fa fa-edit fa-fw"></i> Edit this page</a>
<a href="https://github.com/cortexproject/cortex/issues/new?title=Efficient%20Query%20Parallelism%20in%20Cortex%20with%20Dynamic%20Query%20Splitting" target=_blank><i class="fab fa-github fa-fw"></i> Create documentation issue</a>
<a href=https://github.com/cortexproject/cortex/issues/new target=_blank><i class="fas fa-tasks fa-fw"></i> Create project issue</a></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#introduction>Introduction</a><ul><li><a href=#query-splitting>Query Splitting</a></li><li><a href=#vertical-sharding>Vertical Sharding</a></li></ul></li><li><a href=#introducing-dynamic-query-splitting>Introducing Dynamic Query Splitting</a><ul><li><a href=#1-queuing-and-merge-bottlenecks-from-over-splitting>1. <strong>Queuing and Merge Bottlenecks from Over-Splitting</strong></a></li><li><a href=#2-parallelism-cost-with-query-lookback>2. <strong>Parallelism Cost with Query Lookback</strong></a></li></ul></li><li><a href=#how-to-configure-dynamic-query-splitting>How to Configure Dynamic Query Splitting</a></li><li><a href=#example-configuration>Example Configuration</a><ul><li><a href=#query-1>Query #1</a></li><li><a href=#query-2>Query #2</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div><div class="taxonomy taxonomy-terms-cloud taxo-projects"><h5 class=taxonomy-title>Our Projects</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=/projects/cortex/ data-taxonomy-term=cortex><span class=taxonomy-label>cortex</span><span class=taxonomy-count>5</span></a></li></ul></div><div class="taxonomy taxonomy-terms-cloud taxo-tags"><h5 class=taxonomy-title>Tag Cloud</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=/tags/blog/ data-taxonomy-term=blog><span class=taxonomy-label>blog</span><span class=taxonomy-count>5</span></a></li><li><a class=taxonomy-term href=/tags/community/ data-taxonomy-term=community><span class=taxonomy-label>community</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/cortex/ data-taxonomy-term=cortex><span class=taxonomy-label>cortex</span><span class=taxonomy-count>5</span></a></li><li><a class=taxonomy-term href=/tags/optimization/ data-taxonomy-term=optimization><span class=taxonomy-label>optimization</span><span class=taxonomy-count>3</span></a></li><li><a class=taxonomy-term href=/tags/query/ data-taxonomy-term=query><span class=taxonomy-label>query</span><span class=taxonomy-count>4</span></a></li><li><a class=taxonomy-term href=/tags/rejection/ data-taxonomy-term=rejection><span class=taxonomy-label>rejection</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/updates/ data-taxonomy-term=updates><span class=taxonomy-label>updates</span><span class=taxonomy-count>1</span></a></li></ul></div></aside><main class="col-12 col-md-9 col-xl-8 pl-md-5 pr-md-4" role=main><a class="btn btn-lg -bg-orange td-rss-button d-none d-lg-block" href=/blog/index.xml target=_blank>RSS <i class="fa fa-rss ml-2"></i></a><div class=td-content><h1>Efficient Query Parallelism in Cortex with Dynamic Query Splitting</h1><div class=lead>This article explores the motivations behind adapting dynamic query splitting in Cortex, how the dynamic model works, and how to configure it for more efficient scalable PromQL query execution.</div><div class="td-byline mb-4">By <b>Ahmed Hassan (<a href=https://github.com/afhassan>@afhassan</a>)</b> |
<time datetime=2025-08-12 class=text-muted>Tuesday, August 12, 2025</time></div><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=/tags/blog/ data-taxonomy-term=blog><span class=taxonomy-label>blog</span></a></li><li><a class=taxonomy-term href=/tags/cortex/ data-taxonomy-term=cortex><span class=taxonomy-label>cortex</span></a></li><li><a class=taxonomy-term href=/tags/query/ data-taxonomy-term=query><span class=taxonomy-label>query</span></a></li><li><a class=taxonomy-term href=/tags/optimization/ data-taxonomy-term=optimization><span class=taxonomy-label>optimization</span></a></li></ul></div><div class="taxonomy taxonomy-terms-article taxo-categories"><h5 class=taxonomy-title>Categories:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=/categories/blog/ data-taxonomy-term=blog><span class=taxonomy-label>blog</span></a></li></ul></div></header><h2 id=introduction>Introduction</h2><p>Cortex traditionally relied on <strong>static query splitting</strong> and <strong>static vertical sharding</strong> to optimize the execution of long-range PromQL queries. Static query splitting divides a query into fixed time intervals, while vertical sharding—when applicable—splits the query across subsets of time series. These techniques offered improved parallelism and reduced query latency but were limited by their one-size-fits-all approach. They did not account for differences in query range, lookback behavior, and cardinality—leading to inefficiencies like over-sharding, redundant data fetches, and storage pressure in large or complex queries.</p><p>To address those gaps, Cortex introduced <strong>dynamic query splitting</strong> and <strong>dynamic vertical sharding</strong>—two adaptive mechanisms that intelligently adjust how queries are broken down based on query semantics.</p><p>This article explores the motivations behind this evolution, how the dynamic model works, and how to configure it for more efficient scalable PromQL query execution.</p><h3 id=query-splitting>Query Splitting</h3><p>Query splitting breaks a single long-range query into smaller subqueries based on a configured time interval. For example, given this configuration, a 30-day range query will be split into 30 individual 1-day subqueries:</p><pre tabindex=0><code>query_range:
    split_queries_by_interval: 24h
</code></pre><p>These subqueries are processed in parallel by different queriers, and the results are merged at query-frontend before returning to client. This improved performance for long range queries and helped prevent timeouts and resource exhaustion.</p><h3 id=vertical-sharding>Vertical Sharding</h3><p>Unlike query splitting, which divides a query over time intervals, vertical sharding divides a query across shards of the time series data itself. Each shard processes only a portion of the matched series, reducing memory usage and computational load per querier. This is especially useful for high-cardinality queries where the number of series can reach hundreds of thousands or more.</p><pre tabindex=0><code>limits:
  query_vertical_shard_size: 4
</code></pre><p>For example, suppose the label selector in the following query <code>http_requests_total{job="api"}</code> matches 500,000 distinct time series, each corresponding to different combinations of labels like <code>instance</code>, <code>path</code>, <code>status</code>, and <code>method</code>.</p><pre tabindex=0><code>sum(rate(http_requests_total{job=&#34;api&#34;}[5m])) by (instance)
</code></pre><p>Without vertical sharding, a single querier must fetch and aggregate all 500,000 series. With vertical sharding enabled and configured to 4, the query would be split into 4 shards each processing ~125,000 series. The results are finally merged at query frontend before returning to client.</p><p><img src=/images/blog/2025/query-splitting-and-vertical-sharding.png alt=QuerySplittingAndVerticalSharding></p><h2 id=introducing-dynamic-query-splitting>Introducing Dynamic Query Splitting</h2><p>Cortex <strong>dynamic query splitting</strong> was introduced to address the limitations of static configurations. Instead of applying a fixed split interval uniformly across all queries, the dynamic logic computes an optimal split interval per query—as a multiple of the configured base interval—based on query semantics and configurable constraints. If <strong>dynamic vertical sharding</strong> is also enabled, then both split interval and vertical shard size will be dynamically adjusted for every query.</p><p>The goal is to maximize query parallelism through both horizontal splitting and vertical sharding, while staying within safe and configurable limits that prevent system overload or inefficiency. This is best explained by how dynamic splitting solves two problems:</p><h3 id=1-queuing-and-merge-bottlenecks-from-over-splitting>1. <strong>Queuing and Merge Bottlenecks from Over-Splitting</strong></h3><p>While increasing parallelism through splitting and sharding is generally beneficial, it becomes counterproductive when the number of subqueries or shards far exceeds the number of available queriers.</p><p>The number of splits when using a fixed interval increases with the query’s time range, which is under the user&rsquo;s control. For example:</p><ul><li>With a static split interval of 24 hours, a 7-day query results in 7 horizontal splits</li><li>If the user increased query range to 100 days, the query is split into 100 horizontal splits.</li><li>If vertical sharding is also enabled and configured to use 5 shards (<code>query_vertical_shard_size: 5</code>), each split is further divided—leading to a total of 500 individual shards.</li></ul><p>When the number of shards grows too large:</p><ul><li>Backend workers become saturated, causing subqueries to queue and increasing total latency.</li><li>The query-frontend merges hundreds of partial results, which introduces overhead that can outweigh the benefits of parallelism.</li><li>Overall system throughput degrades, especially when multiple large queries are executed concurrently.</li></ul><p>To solve this issue, a new configuration <code>max_shards_per_query</code> is introduced for the maximum parallelism per query. Given the same example above:</p><ul><li>With a static split interval of 24 hours and <code>max_shards_per_query</code> set to 75, a 7-day query still results in 7 splits.</li><li>If the user increased query range to 100 days, the dynamic splitting algorithm will adjust the split interval to be 48 hours, producing 50 horizontal splits—keeping the total within the target of 75 shards.</li><li>If vertical sharding is enabled and configured to use up to 5 shards, the dynamic logic selects the optimal combination of split interval and vertical shards to maximize parallelism without exceeding 75 shards.<ul><li>In this case, a 96-hour (4-day) split interval with 3 vertical shards yields exactly 75 total shards—the most efficient combination.</li><li>Note: <code>enable_dynamic_vertical_sharding</code> must be set to true; otherwise, only the split interval will be adjusted.</li></ul></li></ul><p>In summary, with dynamic splitting enabled, you can define a target total number of shards, and Cortex will automatically adjust time splitting and vertical sharding to maximize parallelism without crossing that limit.</p><p><img src=/images/blog/2025/query-static-and-dynamic-splitting.png alt=QuerySplittingAndVerticalSharding></p><h3 id=2-parallelism-cost-with-query-lookback>2. <strong>Parallelism Cost with Query Lookback</strong></h3><p>In PromQL, some functions like <code>rate()</code>, <code>increase()</code>, or <code>max_over_time()</code> use a <strong>lookback window</strong>, meaning each query must fetch samples from before the evaluation timestamp to execute.</p><p>Consider the following query that calculates the maximum container memory usage over a 90-day lookback window:</p><pre tabindex=0><code>max_over_time(container_memory_usage_bytes{cluster=&#34;prod&#34;, namespace=&#34;payments&#34;}[90d])
</code></pre><p>Suppose this query is evaluated over a 30-day range and static query splitting is configured to split it into 1-day intervals. This produces 30 subqueries, each corresponding to a single day. However, due to the [90d] range vector:</p><ul><li>Each subquery must fetch the full 90 days of historical data to evaluate correctly.</li><li>The same data blocks are repeatedly fetched across all subqueries</li><li>The total duration of data fetched is <code>query range + (lookback window x total shards)</code>, which results in 30 + 90 x 30 = 2,730 days.</li></ul><p>As a result, store-gateways must handle a large amount of mostly redundant reads, repeatedly fetching data blocks for each subquery. This puts additional pressure on the storage layer, and the cumulative effect slows down query execution and degrades overall system performance. In this case, splitting the query further doesn’t reduce backend load—it amplifies it.</p><p>With dynamic splitting, you can define a target <code>max_fetched_data_duration_per_query</code>—the maximum cumulative duration of historical data that a single query is allowed to fetch. If the lookback window is long, the algorithm automatically increases the split interval or reduces the vertical shard size to lower the shard count and protect the storage layer.</p><p>For example, with <code>max_fetched_data_duration_per_query</code> set to 500d:</p><ul><li>A larger split interval of 120-hour (5-day) is used to split the query into 5 splits.<ul><li>This is the optimal split interval that results in highest parallelism without crossing the limit of 500 days fetched.</li></ul></li><li>The total duration fetched from storage layer becomes 30 + 90 x 5 = 480 days—lower than the target of 500 days.</li></ul><p><img src=/images/blog/2025/query-static-and-dynamic-splitting-lookback.png alt=QuerySplittingAndVerticalSharding></p><h2 id=how-to-configure-dynamic-query-splitting>How to Configure Dynamic Query Splitting</h2><p>Dynamic query splitting is configured under the <code>dynamic_query_splits</code> section in the <code>query_range</code> block of Cortex’s configuration. Keep in mind that it works in conjunction with static <code>split_queries_by_interval</code> and <code>query_vertical_shard_size</code> which are required to be configured as well:</p><p>Dynamic query splitting considers the following configurations:</p><ul><li><p><code>max_shards_per_query:</code> Defines the maximum number of total shards (horizontal splits × vertical shards) that a single query can generate. If <code>enable_dynamic_vertical_sharding</code> is set, the dynamic logic will adjust both the split interval and vertical shard size to find the most effective combination that results in the highest degree of sharding without exceeding this limit.</p></li><li><p><code>max_fetched_data_duration_per_query:</code> Sets a target for the maximum total time duration of data that can be fetched across all subqueries. To keep the duration fetched below this target, a larger split interval and/or less vertical sharding is used. This is especially important for queries with long lookback windows, where excessive splitting can lead to redundant block reads, putting pressure on store-gateways and the storage layer.</p></li><li><p><code>enable_dynamic_vertical_sharding:</code> When enabled, vertical sharding becomes dynamic per query. Instead of using a fixed shard count, an optimal vertical shard size ranging from 1 (no sharding) to the tenant’s configured <code>query_vertical_shard_size</code> will be used.</p></li></ul><h2 id=example-configuration>Example Configuration</h2><p>Let&rsquo;s explore how two different queries will be handled given the following configuration:</p><pre tabindex=0><code>query_range:
  split_queries_by_interval: 24h
  dynamic_query_splits:
    max_shards_per_query: 100
    max_fetched_data_duration_per_query: 8760h # 365 day
    enable_dynamic_vertical_sharding: true

limits:
  query_vertical_shard_size: 4
</code></pre><h3 id=query-1>Query #1</h3><pre tabindex=0><code>sum by (pod) (
  rate(container_cpu_usage_seconds_total{namespace=&#34;prod&#34;}[1m])
)
</code></pre><ul><li><strong>Query time range:</strong> 60 days</li><li><strong>Lookback window:</strong> 1 minute</li></ul><p>Since the query has a short lookback window of 1 min, the total duration of data fetched by each shard is not going to be limiting factor. The limiting factor to consider here is maintaining less than 100 total shards. Both dynamic splitting and dynamic vertical sharding are enabled. Cortex finds the most optimal combination that results in the highest number of shards below 100. In this case:</p><ul><li><strong>Number of splits by time:</strong> 30 (2 day interval)</li><li><strong>Vertical shard size:</strong> 3</li><li><strong>Total shards:</strong> 90</li></ul><h3 id=query-2>Query #2</h3><pre tabindex=0><code>sum by (pod) (
  max_over_time(container_memory_usage_bytes{namespace=&#34;prod&#34;}[30d])
)
</code></pre><ul><li><strong>Query time range:</strong> 14 days</li><li><strong>Lookback window:</strong> 30 days</li></ul><p>This query can be split into 14 splits and sharded vertically by 4 resulting in a total of 56 shards, which is below the limit of 100 total shards. However, since each shard is going to have to fetch all 30 days of the lookback window to evaluate in addition to the interval itself, this would result in 56 shards each fetching 31 days of data for a total of 1736 days. This is not optimal and will cause a heavy load on the backend storage layer.</p><p>Luckily we configured <code>max_fetched_data_duration_per_query</code> to be 365 days. This will limit query sharding to achieve highest parallelism without crossing the duration fetched limit. In this case:</p><ul><li>Number of splits by time: 5 (3 day interval)</li><li>Vertical shard size: 2</li><li>Total shards: 10</li></ul><p>The total duration of data fetched for query evaluation is calculated using <code>(interval + lookback window) x total shards</code>. In this case <code>(3 + 30) x 10 = 330</code> days fetched, which is below our limit of 365 days.</p><h2 id=conclusion>Conclusion</h2><p>Dynamic query splitting and vertical sharding make Cortex smarter about how it executes PromQL queries. By adapting to each query&rsquo;s semantics and backend constraints, Cortex avoids the limitations of static configurations—enabling efficient parallelism across diverse query patterns and consistently delivering high performance at scale.</p><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><li><a href=/blog/2025/08/04/block-the-blast-how-query-rejection-protects-your-cortex-cluster/ aria-label="Previous - Block the Blast: How Query Rejection Protects Your Cortex Cluster" class="btn btn-primary"><span class=mr-1>←</span>Previous</a></li><a href=/blog/2025/09/08/query-priority-in-cortex/ aria-label="Next - Query Priority in Cortex" class="btn btn-primary">Next<span class=ml-1>→</span></a></li></ul></div></main></div></div><footer><div class="row td-box td-box--dark td-box--gradient td-box--height-auto text-white p-5"><div class="col-12 col-sm-4 pb-5 pb-sm-0"><img src=/images/cortex-stacked-white.png width=75px class="img-fluid float-left"></div><div class="col-12 col-sm-4 pb-5 pb-sm-0"><h6 class=font-weight-bold>Community</h6><ul class=list-unstyled><li><a href=https://slack.cncf.io class="text-reset text-white"><i class="fab fa-fw fa-slack"></i> Slack</a></li><li><a href=https://github.com/cortexproject/cortex class="text-reset text-white"><i class="fab fa-fw fa-github"></i> GitHub</a></li><li><a href=https://twitter.com/cortexmetrics class="text-reset text-white"><i class="fab fa-fw fa-twitter"></i> Twitter</a></li></ul></div><div class="col-12 col-sm-4"><h6 class=font-weight-bold>About</h6><p>Cortex is an OSS licensed project as Apache License 2.0</p></div></div><div class="row td-box td-box--dark td-box--gradient td-box--height-auto text-white p-5 text-center"><small class="col-12 text-center">© 2025 The Cortex Authors All Rights Reserved.<br>The Linux Foundation has registered trademarks and uses trademarks.
For a list of trademarks of The Linux Foundation, please see <a class="text-light alert-link" href=https://www.linuxfoundation.org/trademark-usage>Trademark Usage page</a>.</small></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA==" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script>
<script src=/js/main.min.91798a335c881f1b6b805085ba4aa22d1dbd2b0b18d105d05189fa104ddae350.js integrity="sha256-kXmKM1yIHxtrgFCFukqiLR29KwsY0QXQUYn6EE3a41A=" crossorigin=anonymous></script></body></html>