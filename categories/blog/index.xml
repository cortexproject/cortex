<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cortex – blog</title><link>/categories/blog/</link><description>Recent content in blog on Cortex</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Mon, 04 Aug 2025 00:00:00 +0000</lastBuildDate><atom:link href="/categories/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Blog: Block the Blast: How Query Rejection Protects Your Cortex Cluster</title><link>/blog/2025/08/04/block-the-blast-how-query-rejection-protects-your-cortex-cluster/</link><pubDate>Mon, 04 Aug 2025 00:00:00 +0000</pubDate><guid>/blog/2025/08/04/block-the-blast-how-query-rejection-protects-your-cortex-cluster/</guid><description>
&lt;h1 id="introduction">Introduction&lt;/h1>
&lt;p>We had events where a set of seemingly &lt;strong>harmless-looking&lt;/strong> dashboard queries kept slipping just under our limits yet repeatedly &lt;strong>OOM-killing the querier pods&lt;/strong>. Our safeguard mechanisms weren’t enough, and the only hope was that the tenant would either stop those queries or that we’d have to throttle all traffic from that tenant. Usually it wasn’t all traffic causing trouble—it was a small set of queries coming from a specific dashboard or some query with specific characteristics. We wished there was a way to manually specify query characteristics and reject them without throttling everything. &lt;strong>This inspired us to build query rejection&lt;/strong>, a last-resort safety net for operators running multi-tenant Cortex clusters.&lt;/p>
&lt;h2 id="why-limits-arent-enough">Why Limits Aren’t Enough&lt;/h2>
&lt;p>Cortex already includes resource limiting, throttling and other resource safeguards, but these protections can’t cover every edge case. Some limits are enforced too late in the query lifecycle to matter; others are broad and can’t target specific bad actors. As a result, a single heavy query can bypass all service limits and still:&lt;/p>
&lt;ul>
&lt;li>Cause OOM kills that disrupt other tenants.&lt;/li>
&lt;li>Degrade availability or spike latency for everyone.&lt;/li>
&lt;li>Require manual operator intervention to restore normal service.&lt;/li>
&lt;/ul>
&lt;p>We needed a more precise tool—one that lets operators proactively block specific query patterns without harming legitimate traffic.&lt;/p>
&lt;h2 id="what-is-query-rejection">What Is Query Rejection?&lt;/h2>
&lt;p>Think of query rejection as an “emergency stop” in a factory. It sits in front of the query engine and checks each request against a set of operator-defined rules. If a request matches criteria, it’s rejected immediately. This allows you to target the handful of queries that cause trouble without imposing a blanket slowdown on everyone else.&lt;/p>
&lt;p>&lt;strong>Key features:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Per-tenant control:&lt;/strong> It&amp;rsquo;s defined in the tenant limit configuration, which only targets queries from specific tenant. &lt;/li>
&lt;li>&lt;strong>Precise matching:&lt;/strong> You can specify different query attributes to narrow down to specific queries. All fields within a rule set must match (AND logic). If needed, you can define multiple independent rule sets to target different types of queries.&lt;/li>
&lt;li>&lt;strong>Pre-processing enforcement:&lt;/strong> Query rejection is applied before the query is executed, allowing known-bad patterns to be blocked before consuming any resources.&lt;/li>
&lt;/ul>
&lt;h2 id="matching-criteria">Matching Criteria&lt;/h2>
&lt;p>Heavy queries often share identifiable traits. Query rejection lets you match on a variety of attributes and reject only those requests. You can combine as many of these as needed:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>API type:&lt;/strong> &lt;code>query&lt;/code>, &lt;code>query_range&lt;/code>, &lt;code>series&lt;/code>, etc.&lt;/li>
&lt;li>&lt;strong>Query string (regex):&lt;/strong> Match by pattern, e.g., any query containing “ALERT”.&lt;/li>
&lt;li>&lt;strong>Time range:&lt;/strong> Match queries whose range falls between a configured &lt;strong>min&lt;/strong> and &lt;strong>max&lt;/strong>.&lt;/li>
&lt;li>&lt;strong>Time window:&lt;/strong> Match queries based on how far their time window is from now by specifying relative &lt;strong>min&lt;/strong> and &lt;strong>max&lt;/strong> boundaries. This is often used to distinguish queries that hit hot storage versus cold storage.&lt;/li>
&lt;li>&lt;strong>Step value (resolution):&lt;/strong> Block extremely fine resolutions (e.g., steps under 5s).&lt;/li>
&lt;li>&lt;strong>Headers:&lt;/strong> Match by User-Agent, Grafana dashboard UID (&lt;code>X-Dashboard-Uid&lt;/code>) or panel ID (&lt;code>X-Panel-Id&lt;/code>).&lt;/li>
&lt;/ul>
&lt;p>By combining these fields, you can zero in on the exact query patterns causing problems without over-blocking.&lt;/p>
&lt;h2 id="configuring-query-rejection">Configuring Query Rejection&lt;/h2>
&lt;p>You define query rejection rules per tenant in a runtime config file. Each rule specifies a set of attributes that must all match for the query to be rejected. The configuration supports multiple such rule sets.&lt;/p>
&lt;p>Here’s an example configuration:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># runtime_config.yaml&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">overrides&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;lt;tenant_id&amp;gt;&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">query_rejection&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">enabled&lt;/span>: &lt;span style="color:#66d9ef">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">query_attributes&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#f92672">api_type&lt;/span>: &lt;span style="color:#ae81ff">query_range&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">regex&lt;/span>: &lt;span style="color:#ae81ff">.*ALERT.*&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">query_step_limit&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">min&lt;/span>: &lt;span style="color:#ae81ff">6s&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">max&lt;/span>: &lt;span style="color:#ae81ff">20s&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">dashboard_uid&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;dash123&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>What this does:&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>&lt;code>enabled&lt;/code> This allows you to temporarily turn off query rejection without removing the configuration. It can help verify whether previously blocked queries are still causing issues.&lt;/li>
&lt;li>&lt;code>query_attributes&lt;/code> is a list of rejection rules. A query will only be rejected if it matches all attributes within one rejection rule.&lt;/li>
&lt;/ul>
&lt;p>In the example above, the single rejection rule requires the following:&lt;/p>
&lt;ul>
&lt;li>API type must be &lt;code>query_range&lt;/code>.&lt;/li>
&lt;li>The query string must contain the word &lt;code>ALERT&lt;/code>.&lt;/li>
&lt;li>The step must be between 6 and 20 seconds.&lt;/li>
&lt;li>The request must come from a dashboard with UID &lt;code>dash123&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>If all of these conditions match, the request is rejected with a &lt;code>422&lt;/code> response. If even one condition doesn’t match, the query is allowed to run. You can define additional rejection rules in the list to target different patterns.&lt;/p>
&lt;h2 id="practical-example">Practical Example&lt;/h2>
&lt;p>Imagine a dashboard panel that repeatedly hits your cluster with a query like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>curl &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> &lt;span style="color:#e6db74">&amp;#39;http://localhost:8005/prometheus/api/v1/query?query=customALERTquery&amp;amp;start=1718383304&amp;amp;end=1718386904&amp;amp;step=7s&amp;#39;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -H &lt;span style="color:#e6db74">&amp;#34;User-Agent: other&amp;#34;&lt;/span> &lt;span style="color:#ae81ff">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#ae81ff">&lt;/span> -H &lt;span style="color:#e6db74">&amp;#34;X-Dashboard-Uid: dash123&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Because this request matches all the configured attributes, it will be blocked. But if even one field is different—such as a longer step duration or a different dashboard UID—the query will go through.&lt;/p>
&lt;h2 id="best-practices-and-cautions">Best Practices and Cautions&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Start with narrow rules.&lt;/strong> Use the most specific fields first—like panel ID or dashboard UID—to reduce risk of over-blocking.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Monitor rejections.&lt;/strong> Use the &lt;code>cortex_query_frontend_rejected_queries_total&lt;/code> metric to track rejected queries, and check logs for detailed query information.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Communicate with tenants.&lt;/strong> Let affected tenants know if their queries are being blocked, and help them adjust their dashboards accordingly.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>When traditional safeguards fall short, query rejection gives operators precise control to block only what’s harmful—without slowing down everything else.&lt;/p>
&lt;p>If you operate a shared Cortex environment, consider learning how to use query rejection effectively. It might just save you from the next incident—by preventing OOM kills, degraded performance, or disruption to other tenants.&lt;/p></description></item><item><title>Blog: Optimizing PromQL queries: A deep dive</title><link>/blog/2025/04/29/optimizing-promql-queries-a-deep-dive/</link><pubDate>Tue, 29 Apr 2025 00:00:00 +0000</pubDate><guid>/blog/2025/04/29/optimizing-promql-queries-a-deep-dive/</guid><description>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>This guide explains how Cortex evaluates PromQL queries, details how time series data is stored and retrieved, and offers strategies to write performant queries — particularly in high-cardinality environments.&lt;/p>
&lt;p>Note: If you are new to PromQL, it is recommended to start with the &lt;a href="https://prometheus.io/docs/prometheus/latest/querying/basics/">Querying basics documentation&lt;/a>.&lt;/p>
&lt;h2 id="prometheus-concepts">Prometheus Concepts&lt;/h2>
&lt;h3 id="data-model">Data Model&lt;/h3>
&lt;p>Prometheus employs a straightforward data model:&lt;/p>
&lt;ul>
&lt;li>Each time series is uniquely identified by a metric name and a set of label-value pairs.&lt;/li>
&lt;li>Each sample includes:
&lt;ul>
&lt;li>A millisecond precision timestamp&lt;/li>
&lt;li>A 64 bit floating point value.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="label-matchers">Label Matchers&lt;/h3>
&lt;p>Label matchers define the selection criteria for time series within the TSDB. Consider the following PromQL expression:&lt;/p>
&lt;pre tabindex="0">&lt;code>http_requests_total{cluster=&amp;#34;prod&amp;#34;, job=&amp;#34;envoy&amp;#34;}
&lt;/code>&lt;/pre>&lt;p>the label matchers are:&lt;/p>
&lt;ul>
&lt;li>&lt;code>__name__=&amp;quot;http_requests_total&amp;quot;&lt;/code>&lt;/li>
&lt;li>&lt;code>cluster=&amp;quot;prod&amp;quot;&lt;/code>&lt;/li>
&lt;li>&lt;code>job=&amp;quot;envoy&amp;quot;&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Prometheus supports four types of label matchers:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Type&lt;/th>
&lt;th>Syntax&lt;/th>
&lt;th>Example&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Equal&lt;/td>
&lt;td>label=&amp;ldquo;value&amp;rdquo;&lt;/td>
&lt;td>job=&amp;ldquo;envoy&amp;rdquo;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Not Equal&lt;/td>
&lt;td>label!=&amp;ldquo;value&amp;rdquo;&lt;/td>
&lt;td>job!=&amp;ldquo;prometheus&amp;rdquo;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Regex Equal&lt;/td>
&lt;td>label=~&amp;ldquo;regex&amp;rdquo;&lt;/td>
&lt;td>job=~&amp;ldquo;env.*&amp;rdquo;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Regex Not Equal&lt;/td>
&lt;td>label!~&amp;ldquo;regex&amp;rdquo;&lt;/td>
&lt;td>status!~&amp;ldquo;4..&amp;rdquo;&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="time-series-storage-in-cortex">Time Series Storage in Cortex&lt;/h2>
&lt;p>Cortex uses Prometheus&amp;rsquo;s Time Series Database (TSDB) for storing time series data. The Prometheus TSDB is time partitioned into blocks. Each TSDB block is made up of the following files:&lt;/p>
&lt;ul>
&lt;li>&lt;code>ID&lt;/code> - ID of the block (&lt;a href="https://github.com/ulid/spec">ULID&lt;/a>)&lt;/li>
&lt;li>&lt;code>meta.json&lt;/code> - Contains the metadata of the block&lt;/li>
&lt;li>&lt;code>index&lt;/code> - A binary file that contains the index&lt;/li>
&lt;li>&lt;code>chunks&lt;/code> - Directory containing the chunk segment files&lt;/li>
&lt;/ul>
&lt;p>More details: &lt;a href="https://github.com/prometheus/prometheus/blob/5630a3906ace8f2ecd16e7af7fb184e4f4dd853d/tsdb/docs/format/README.md">TSDB format docs&lt;/a>&lt;/p>
&lt;h3 id="index-file">Index File&lt;/h3>
&lt;p>The &lt;code>index&lt;/code> file contains two key mappings for query processing:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Postings Offset Table and Postings&lt;/strong>: Maps label-value pairs to Series IDs&lt;/li>
&lt;li>&lt;strong>Series Section&lt;/strong>: Maps series IDs to label sets and chunk references&lt;/li>
&lt;/ul>
&lt;h4 id="example">Example&lt;/h4>
&lt;p>Given the following time series:&lt;/p>
&lt;pre tabindex="0">&lt;code>http_requests_total{cluster=&amp;#34;prod&amp;#34;, job=&amp;#34;envoy&amp;#34;, status=&amp;#34;200&amp;#34;} -&amp;gt; SeriesID(1)
http_requests_total{cluster=&amp;#34;prod&amp;#34;, job=&amp;#34;envoy&amp;#34;, status=&amp;#34;400&amp;#34;} -&amp;gt; SeriesID(2)
http_requests_total{cluster=&amp;#34;prod&amp;#34;, job=&amp;#34;envoy&amp;#34;, status=&amp;#34;500&amp;#34;} -&amp;gt; SeriesID(3)
http_requests_total{cluster=&amp;#34;prod&amp;#34;, job=&amp;#34;prometheus&amp;#34;, status=&amp;#34;200&amp;#34;} -&amp;gt; SeriesID(4)
&lt;/code>&lt;/pre>&lt;p>The index file would store mappings such as:&lt;/p>
&lt;pre tabindex="0">&lt;code>__name__=http_requests_total → [1, 2, 3, 4]
cluster=prod → [1, 2, 3, 4]
job=envoy → [1, 2, 3]
job=prometheus → [4]
status=200 → [1, 4]
status=400 → [2]
status=500 → [3]
&lt;/code>&lt;/pre>&lt;h3 id="chunks">Chunks&lt;/h3>
&lt;p>Each chunk segment file can store up to &lt;strong>512MB&lt;/strong> of data. Each chunk in the segment file typically holds up to &lt;strong>120 samples&lt;/strong>.&lt;/p>
&lt;h2 id="query-execution-in-cortex">Query Execution in Cortex&lt;/h2>
&lt;p>To optimize PromQL queries effectively, it is essential to understand how queries are executed within Cortex. Consider the following example:&lt;/p>
&lt;pre tabindex="0">&lt;code>sum(rate(http_requests_total{cluster=&amp;#34;prod&amp;#34;, job=&amp;#34;envoy&amp;#34;}[5m]))
&lt;/code>&lt;/pre>&lt;h3 id="block-selection">Block Selection&lt;/h3>
&lt;p>Cortex first identifies the TSDB blocks that fall within the query’s time range. This process is very fast in Cortex and will not add a huge overhead on query execution.&lt;/p>
&lt;h3 id="series-selection">Series Selection&lt;/h3>
&lt;p>Next, Cortex uses the inverted index to retrieve the set of matching series IDs for each label matcher. For example:&lt;/p>
&lt;pre tabindex="0">&lt;code>__name__=&amp;#34;http_requests_total&amp;#34; → [1, 2, 3, 4]
cluster=&amp;#34;prod&amp;#34; → [1, 2, 3, 4]
job=&amp;#34;envoy&amp;#34; → [1, 2, 3]
&lt;/code>&lt;/pre>&lt;p>The intersection of these sets yields:&lt;/p>
&lt;pre tabindex="0">&lt;code>http_requests_total{cluster=“prod”, job=“envoy”, status=“200”}
http_requests_total{cluster=“prod”, job=“envoy”, status=“400”}
http_requests_total{cluster=“prod”, job=“envoy”, status=“500”}
&lt;/code>&lt;/pre>&lt;h3 id="sample-selection">Sample Selection&lt;/h3>
&lt;p>The mapping from series to chunks is used to identify the relevant chunks from the chunk segment files. These chunks are decoded to retrieve the underlying time series samples.&lt;/p>
&lt;h3 id="promql-evaluation">PromQL evaluation&lt;/h3>
&lt;p>Using the retrieved series and samples, the PromQL engine evaluates the query. There are two modes of running queries:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Instant queries&lt;/strong> – Evaluated at a single timestamp&lt;/li>
&lt;li>&lt;strong>Range queries&lt;/strong> – Evaluated at regular intervals over a defined time range&lt;/li>
&lt;/ul>
&lt;h2 id="common-causes-of-slow-queries-and-optimization-techniques">Common Causes of Slow Queries and Optimization Techniques&lt;/h2>
&lt;p>Several factors influence the latency and resource usage of PromQL queries. This section highlights the key contributors and practical strategies for improving performance.&lt;/p>
&lt;h3 id="query-cardinality">Query Cardinality&lt;/h3>
&lt;p>High cardinality increases the number of time series that must be scanned and evaluated.&lt;/p>
&lt;h4 id="recommendations">Recommendations&lt;/h4>
&lt;ul>
&lt;li>Eliminate unnecessary labels from metrics.&lt;/li>
&lt;li>Use selective label matchers to reduce the number of series returned.&lt;/li>
&lt;/ul>
&lt;h3 id="number-of-samples-processed">Number of samples processed&lt;/h3>
&lt;p>The number of samples fetched impacts both memory usage and CPU time for decoding and processing.&lt;/p>
&lt;h4 id="recommendations-1">Recommendations&lt;/h4>
&lt;p>Until downsampling is implemented, reducing the scrape interval can help lower the amount of samples to be processed. But this comes at the cost of reduced resolution.&lt;/p>
&lt;h3 id="number-of-evaluation-steps">Number of evaluation steps&lt;/h3>
&lt;p>The number of evaluation steps for a range query is computed as:&lt;/p>
&lt;pre tabindex="0">&lt;code>num of steps = 1 + (end - start) / step
&lt;/code>&lt;/pre>&lt;p>&lt;strong>Example:&lt;/strong> A 24-hour query with a 1-minute step results in 1,441 evaluation steps.&lt;/p>
&lt;h4 id="recommendations-2">Recommendations&lt;/h4>
&lt;p>Grafana can automatically set the step size based on the time range. If a query is slow, manually increasing the step parameter can reduce computational overhead.&lt;/p>
&lt;h3 id="time-range-of-the-query">Time range of the query&lt;/h3>
&lt;p>Wider time ranges amplify the effects of cardinality, sample volume, and evaluation steps.&lt;/p>
&lt;h4 id="recommendations-3">Recommendations&lt;/h4>
&lt;ul>
&lt;li>Use shorter time ranges (e.g., 1h) in dashboards.&lt;/li>
&lt;li>Default to instant queries during metric exploration to reduce load.&lt;/li>
&lt;/ul>
&lt;h3 id="query-complexity">Query Complexity&lt;/h3>
&lt;p>Subqueries, nested expressions, and advanced functions may lead to substantial CPU consumption.&lt;/p>
&lt;h4 id="recommendations-4">Recommendations&lt;/h4>
&lt;ul>
&lt;li>Simplify complex expressions where feasible.&lt;/li>
&lt;/ul>
&lt;h3 id="regular-expressions">Regular Expressions&lt;/h3>
&lt;p>While Prometheus has optimized regex matching, such queries remain CPU-intensive.&lt;/p>
&lt;h4 id="recommendations-5">Recommendations&lt;/h4>
&lt;ul>
&lt;li>Avoid regex matchers in high-frequency queries.&lt;/li>
&lt;li>Where possible, use equality matchers instead.&lt;/li>
&lt;/ul>
&lt;h3 id="query-result-size">Query Result Size&lt;/h3>
&lt;p>Queries returning large datasets (&amp;gt;100MB) can incur significant serialization and network transfer costs.&lt;/p>
&lt;h4 id="example-1">Example&lt;/h4>
&lt;pre tabindex="0">&lt;code>pod_container_info #No aggregation
sum by (pod) (rate(container_cpu_seconds_total[1m])) # High cardinality result
&lt;/code>&lt;/pre>&lt;h4 id="recommendations-6">Recommendations&lt;/h4>
&lt;ul>
&lt;li>Scoping the query using additional label matchers reduces result size and improves performance.&lt;/li>
&lt;/ul>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>The key optimization techniques are:&lt;/p>
&lt;ul>
&lt;li>Use selective label matchers to limit cardinality.&lt;/li>
&lt;li>Increase the step value in long-range queries.&lt;/li>
&lt;li>Simplify complex or nested PromQL expressions.&lt;/li>
&lt;li>Avoid regex matchers unless strictly necessary.&lt;/li>
&lt;li>Favor instant queries for interactive use cases.&lt;/li>
&lt;li>Scope queries to minimize the result size.&lt;/li>
&lt;/ul></description></item><item><title>Blog: Introducing the Cortex Blog: Sharing Our Journey</title><link>/blog/2025/04/26/introducing-the-cortex-blog-sharing-our-journey/</link><pubDate>Sat, 26 Apr 2025 00:00:00 +0000</pubDate><guid>/blog/2025/04/26/introducing-the-cortex-blog-sharing-our-journey/</guid><description>
&lt;p>Welcome to the official Cortex blog!&lt;/p>
&lt;p>We’re kicking things off here to share updates, best practices,
technical deep-dives, and community highlights around everything Cortex.
Whether you&amp;rsquo;re operating a Cortex cluster, integrating it into your observability platform,
or just starting to explore scalable time-series databases — you&amp;rsquo;re in the right place.&lt;/p>
&lt;p>In the coming weeks, you can expect posts on:&lt;/p>
&lt;ul>
&lt;li>Real-world Cortex deployment strategies and lessons learned&lt;/li>
&lt;li>Tips for running Cortex efficiently at scale&lt;/li>
&lt;li>Deep dives into key Cortex concepts like blocks storage, ruler sharding, and query federation&lt;/li>
&lt;li>Guides to help new contributors get involved with the project&lt;/li>
&lt;li>Interviews with maintainers and users from across the community&lt;/li>
&lt;li>Roadmap insights and upcoming features we&amp;rsquo;re excited about&lt;/li>
&lt;/ul>
&lt;p>Cortex has grown a lot thanks to a vibrant community of operators, contributors, and partners.
This blog will be another space for us to connect, learn from each other, and push the project even further.&lt;/p>
&lt;p>Stay tuned — the first technical post is coming soon!&lt;/p>
&lt;p>If there&amp;rsquo;s a topic you’d love to see covered, feel free to reach out or open a discussion in our &lt;a href="https://github.com/cortexproject/cortex/discussions">Cortex community forums&lt;/a>.&lt;/p>
&lt;p>Thanks for being part of the journey! 🚀&lt;/p>
&lt;p>— The Cortex Team&lt;/p></description></item></channel></rss>